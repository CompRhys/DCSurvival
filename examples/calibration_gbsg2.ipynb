{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from .gbsg2 import load_gbsg2\n",
    "\n",
    "dataset = load_gbsg2(df=True).astype(\"float32\")\n",
    "\n",
    "N = dataset.shape[0]\n",
    "\n",
    "time_column = \"time\"\n",
    "event_column = \"cens\"\n",
    "features = np.setdiff1d(dataset.columns, [time_column, event_column] ).tolist()\n",
    "\n",
    "# Building training and testing sets\n",
    "index_train, index_test = train_test_split( range(N), test_size = 0.1, random_state = 142857, stratify = dataset[event_column])\n",
    "data_train = dataset.loc[index_train].reset_index( drop = True )\n",
    "data_test  = dataset.loc[index_test].reset_index( drop = True )\n",
    "N2 = data_train.shape[0]\n",
    "\n",
    "index_train, index_val = train_test_split( range(N2), test_size = 0.1, random_state = 142857, stratify = data_train[event_column])\n",
    "data_train = dataset.loc[index_train].reset_index( drop = True )\n",
    "data_val  = dataset.loc[index_val].reset_index( drop = True )\n",
    "\n",
    "# Creating the X, T and E inputs\n",
    "X_train, X_test, X_val = data_train[features], data_test[features], data_val[features]\n",
    "time_train, time_test, time_val = data_train[time_column], data_test[time_column], data_val[time_column]\n",
    "event_train, event_test, event_val = data_train[event_column], data_test[event_column], data_val[event_column]\n",
    "\n",
    "\n",
    "# X1_reshape = X\n",
    "# X1_reshape_t = X_t\n",
    "# delta = e\n",
    "# delta_t = e_t\n",
    "# y = t\n",
    "# y_t = t_t\n",
    "\n",
    "step = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSF\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "bool_indicator_train =  [bool(x) for x in event_train]\n",
    "y_train_tuple =  c = np.array(list(zip(bool_indicator_train, time_train)), dtype=[(\"a\", bool), (\"b\", float)])\n",
    "rsf = RandomSurvivalForest(n_estimators=50, min_samples_split=10, \n",
    "                            min_samples_leaf=15, n_jobs=16)\n",
    "rsf.fit(X_train, y_train_tuple)\n",
    "rsf_func = rsf.predict_survival_function(X_test)\n",
    "# survprob_rsf= np.array(1-rsf.predict_survival_function(X_test, times = np.arange(time_test.min(),time_test.max(),step)).T)\n",
    "times = np.arange(time_test.min(),time_test.max(),step)\n",
    "survprob_rsf = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    survprob_rsf.append(1- rsf_func[i](times))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CoxPH\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "bool_indicator_train =  [bool(x) for x in event_train]\n",
    "y_train_tuple =  c = np.array(list(zip(bool_indicator_train, time_train)), dtype=[(\"a\", bool), (\"b\", float)])\n",
    "CoxPH = CoxPHSurvivalAnalysis(alpha=0,verbose=0)\n",
    "\n",
    "CoxPH.fit(X_train, y_train_tuple)\n",
    "coxph_func = CoxPH.predict_survival_function(X_test)\n",
    "# survprob_rsf= np.array(1-rsf.predict_survival_function(X_test, times = np.arange(time_test.min(),time_test.max(),step)).T)\n",
    "times = np.arange(time_test.min(),time_test.max(),step)\n",
    "survprob_coxph = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    survprob_coxph.append(1- coxph_func[i](times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepSurv\n",
    "from pycox.models import CoxPH\n",
    "import torchtuples as tt\n",
    "import torch\n",
    "batch_size = 4096\n",
    "epochs = 10000\n",
    "\n",
    "y_train_tuple = (time_train.to_numpy(), event_train.to_numpy())\n",
    "y_val_tuple = (time_val.to_numpy(), event_val.to_numpy())\n",
    "val = X_val.to_numpy(), y_val_tuple\n",
    "in_features = X_train.shape[1]\n",
    "num_nodes = [32, 32, 32]\n",
    "out_features = 1\n",
    "batch_norm = True\n",
    "dropout = 0.0\n",
    "output_bias = False\n",
    "\n",
    "net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm,\n",
    "                            dropout, output_bias=output_bias)\n",
    "deepsurv = CoxPH(net, tt.optim.Adam, device=torch.device(\"cpu\"))\n",
    "deepsurv.optimizer.set_lr(0.001)\n",
    "callbacks = [tt.callbacks.EarlyStopping(patience=100)]\n",
    "verbose = False\n",
    "log = deepsurv.fit(X_train.to_numpy(), y_train_tuple, batch_size, epochs, callbacks, verbose,\n",
    "                val_data=val, val_batch_size=batch_size)\n",
    "_ = deepsurv.compute_baseline_hazards()\n",
    "deepsurv_pred = deepsurv.predict_surv_df(X_test.to_numpy())\n",
    "prediction_timepoint = deepsurv_pred.index\n",
    "\n",
    "survprob_deepsurv = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    temp_list = []\n",
    "    for time in prediction_timepoint:\n",
    "        temp_list.append( 1- deepsurv_pred[i][time] )\n",
    "    survprob_deepsurv.append(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CoxCC\n",
    "from pycox.models import CoxCC\n",
    "import torchtuples as tt\n",
    "import torch\n",
    "batch_size = 4096\n",
    "epochs = 10000\n",
    "\n",
    "y_train_tuple = (time_train.to_numpy(), event_train.to_numpy())\n",
    "y_val_tuple = (time_val.to_numpy(), event_val.to_numpy())\n",
    "val = X_val.to_numpy(), y_val_tuple\n",
    "in_features = X_train.shape[1]\n",
    "num_nodes = [32, 32, 32]\n",
    "out_features = 1\n",
    "batch_norm = True\n",
    "dropout = 0.0\n",
    "output_bias = False\n",
    "\n",
    "net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm,\n",
    "                            dropout, output_bias=output_bias)\n",
    "coxcc = CoxCC(net, tt.optim.Adam, device=torch.device(\"cpu\"))\n",
    "coxcc.optimizer.set_lr(0.001)\n",
    "callbacks = [tt.callbacks.EarlyStopping(patience=100)]\n",
    "verbose = False\n",
    "log = coxcc.fit(X_train.to_numpy(), y_train_tuple, batch_size, epochs, callbacks, verbose,\n",
    "                val_data=val, val_batch_size=batch_size)\n",
    "_ = coxcc.compute_baseline_hazards()\n",
    "coxcc_pred = coxcc.predict_surv_df(X_test.to_numpy())\n",
    "prediction_timepoint = coxcc_pred.index\n",
    "\n",
    "survprob_coxcc = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    temp_list = []\n",
    "    for time in prediction_timepoint:\n",
    "        temp_list.append( 1- coxcc_pred[i][time] )\n",
    "    survprob_coxcc.append(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepHit\n",
    "from pycox.models import DeepHitSingle\n",
    "import torchtuples as tt\n",
    "import torch\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "num_durations = 400\n",
    "batch_size = 4096\n",
    "epochs = 10000\n",
    "\n",
    "labtrans = DeepHitSingle.label_transform(num_durations)\n",
    "y_train_tuple = labtrans.fit_transform(time_train.to_numpy(), event_train.to_numpy())\n",
    "y_val_tuple = labtrans.fit_transform(time_val.to_numpy(), event_val.to_numpy())\n",
    "val = X_val.to_numpy(), y_val_tuple\n",
    "\n",
    "in_features = X_train.shape[1]\n",
    "num_nodes = [32, 32, 32]\n",
    "out_features = num_durations\n",
    "batch_norm = True\n",
    "dropout = 0.0\n",
    "net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout)\n",
    "deephit = DeepHitSingle(net, tt.optim.Adam, alpha=0.2, sigma=0.1, duration_index=labtrans.cuts, device=device)\n",
    "deephit.optimizer.set_lr(0.001)\n",
    "callbacks = [tt.callbacks.EarlyStopping(patience=100)]\n",
    "verbose = False\n",
    "log = deephit.fit(X_train.to_numpy(), y_train_tuple, batch_size, epochs, callbacks, verbose, val_data=val, val_batch_size=batch_size)\n",
    "deephit_pred = deephit.predict_surv_df(X_test.to_numpy())\n",
    "prediction_timepoint = deephit_pred.index\n",
    "\n",
    "survprob_deephit = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    temp_list = []\n",
    "    for time in prediction_timepoint:\n",
    "        temp_list.append( 1- deephit_pred[i][time] )\n",
    "    survprob_deephit.append(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycox.models import PCHazard\n",
    "import torchtuples as tt\n",
    "import torch\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batch_size = 4096\n",
    "epochs = 10000\n",
    "num_durations = 400\n",
    "\n",
    "labtrans = PCHazard.label_transform(num_durations)\n",
    "y_train_tuple = labtrans.fit_transform(time_train.to_numpy(), event_train.to_numpy())\n",
    "y_val_tuple = labtrans.fit_transform(time_val.to_numpy(), event_val.to_numpy())\n",
    "val = X_val.to_numpy(), y_val_tuple\n",
    "\n",
    "in_features = X_train.shape[1]\n",
    "num_nodes = [100,100,100]\n",
    "out_features = labtrans.out_features\n",
    "batch_norm = False\n",
    "dropout = 0.0\n",
    "net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout)\n",
    "pchazard = PCHazard(net, tt.optim.Adam, device=device)\n",
    "pchazard.optimizer.set_lr(0.0001)\n",
    "callbacks = [tt.callbacks.EarlyStopping(patience=200)]\n",
    "verbose = False\n",
    "log = pchazard.fit(X_train.to_numpy(), y_train_tuple, batch_size, epochs, callbacks, verbose, val_data=val, val_batch_size=batch_size)\n",
    "pchazard_pred = pchazard.predict_surv_df(X_test.to_numpy())\n",
    "prediction_timepoint = pchazard_pred.index\n",
    "\n",
    "survprob_pchazard = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    temp_list = []\n",
    "    for time in prediction_timepoint:\n",
    "        temp_list.append( 1- pchazard_pred[i][time] )\n",
    "    survprob_pchazard.append(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dcsurvival.dirac_phi import DiracPhi\n",
    "from dcsurvival.survival import SurvivalCopula_sumofull\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.set_num_threads(16)\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "depth = 2\n",
    "widths = [100, 100]\n",
    "lc_w_range = (0, 1.0)\n",
    "shift_w_range = (0., 2.0)\n",
    "num_epochs = 100000\n",
    "batch_size = 30000\n",
    "early_stop_epochs = 1000\n",
    "\n",
    "times_tensor_train = torch.tensor(time_train.to_numpy(), dtype=torch.float64).to(device)\n",
    "event_indicator_tensor_train = torch.tensor(event_train.to_numpy(), dtype=torch.float64).to(device)\n",
    "covariate_tensor_train = torch.tensor(X_train.to_numpy(), dtype=torch.float64).to(device)\n",
    "\n",
    "times_tensor_val = torch.tensor(time_val.to_numpy(), dtype=torch.float64).to(device)\n",
    "event_indicator_tensor_val = torch.tensor(event_val.to_numpy(), dtype=torch.float64).to(device)\n",
    "covariate_tensor_val = torch.tensor(X_val.to_numpy(), dtype=torch.float64).to(device)\n",
    "\n",
    "phi = DiracPhi(depth, widths, lc_w_range, shift_w_range, device, tol = 1e-14).to(device)\n",
    "model = SurvivalCopula_sumofull(phi, device = device, num_features=X_train.shape[1], tol=1e-14, hidden_size = 100).to(device)\n",
    "optimizer = optim.AdamW([{\"params\": model.sumo_e.parameters(), \"lr\": 1e-5},\n",
    "                        {\"params\": model.sumo_c.parameters(), \"lr\": 1e-5},\n",
    "                        {\"params\": model.phi.parameters(), \"lr\": 1e-5}\n",
    "                    ])\n",
    "# # Train the model\n",
    "# best_val_loglikelihood = float(\"-inf\")\n",
    "# epochs_no_improve = 0\n",
    "# # for epoch in tqdm(range(num_epochs)):\n",
    "# for epoch in range(num_epochs):\n",
    "#     optimizer.zero_grad()\n",
    "#     logloss = model(covariate_tensor_train, times_tensor_train, event_indicator_tensor_train, max_iter = 10000)\n",
    "#     (-logloss).backward() \n",
    "#     optimizer.step()\n",
    "#     if epoch % 100 == 0 and epoch > 0:\n",
    "#         print(\"epoch\", epoch, \"train loglikelihood\", logloss.item())\n",
    "#         val_loglikelihood = model(covariate_tensor_val, times_tensor_val, event_indicator_tensor_val, max_iter = 10000)\n",
    "#         print(\"val likelihood\", val_loglikelihood.item())\n",
    "#         if val_loglikelihood > (best_val_loglikelihood ):\n",
    "#             best_val_loglikelihood = val_loglikelihood\n",
    "#             epochs_no_improve = 0\n",
    "#             torch.save({\"epoch\": epoch, \"model_state_dict\": model.state_dict(),\"loss\": best_val_loglikelihood,\n",
    "#                         }, \"/home/SurvivalACNet_sumo/checkpoints/weight.pth\")\n",
    "#         else:\n",
    "#             if val_loglikelihood > best_val_loglikelihood:\n",
    "#                 best_val_loglikelihood = val_loglikelihood\n",
    "#             epochs_no_improve = epochs_no_improve + 100\n",
    "#     # Early stopping condition\n",
    "#     if epochs_no_improve == early_stop_epochs:\n",
    "#         # print(\"Early stopping triggered at epoch: %s\" % epoch)\n",
    "#         break\n",
    "# # load the best model\n",
    "checkpoint = torch.load(\"/home/SurvivalACNet_sumo/checkpoints/weight.pth\")\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.arange(time_test.min(),time_test.max(),step)\n",
    "times_tensor = torch.tensor(times).to(device)\n",
    "covariate_tensor_test = torch.tensor(X_test.to_numpy(), dtype=torch.float64).to(device)\n",
    "\n",
    "survprob_matrix_list = []\n",
    "\n",
    "for time in times_tensor:\n",
    "    temp = 1- model.survival(time, covariate_tensor_test).cpu().detach().numpy()\n",
    "    survprob_matrix_list.append(temp)\n",
    "\n",
    "survprob_matrix = np.vstack(survprob_matrix_list)\n",
    "print(survprob_matrix.shape)\n",
    "survprob_dcsurvival = list(survprob_matrix.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_l is the event time\n",
    "y_l = []\n",
    "prob_rsf = []\n",
    "prob_coxph=[]\n",
    "prob_deepsurv = []\n",
    "prob_deephit = []\n",
    "prob_pchazard = []\n",
    "prob_coxcc = []\n",
    "prob_dcsurvival = []\n",
    "for j in range(len(survprob_rsf)): #\n",
    "    k = 0\n",
    "    for i in np.arange(time_test.min(),time_test.max(),step): # from min to max of test time, the number of steps\n",
    "        if k < len(survprob_rsf[0]):\n",
    "            if i <= time_test[j]:\n",
    "                y_l.append(0)\n",
    "            else:\n",
    "                y_l.append(1)\n",
    "            prob_rsf.append(survprob_rsf[j][k])\n",
    "            prob_coxph.append(survprob_coxph[j][k])\n",
    "            k+=1\n",
    "        else: \n",
    "            break\n",
    "\n",
    "for j in range(len(survprob_deepsurv)): #\n",
    "    k = 0\n",
    "    for i in np.arange(time_test.min(),time_test.max(),step): # from min to max of test time, the number of steps\n",
    "        if k < len(survprob_deepsurv[0]):\n",
    "            prob_deepsurv.append(survprob_deepsurv[j][k])\n",
    "            prob_deephit.append(survprob_deephit[j][k])\n",
    "            prob_pchazard.append(survprob_pchazard[j][k])\n",
    "            prob_coxcc.append(survprob_coxcc[j][k])\n",
    "            prob_dcsurvival.append(survprob_dcsurvival[j][k])\n",
    "            k+=1\n",
    "        else: \n",
    "            break\n",
    "             \n",
    "y_l = np.array(y_l)\n",
    "prob_rsf = np.array(prob_rsf)\n",
    "prob_coxph = np.array(prob_coxph)\n",
    "prob_deepsurv = np.array(prob_deepsurv)\n",
    "prob_deephit = np.array(prob_deephit)\n",
    "prob_pchazard = np.array(prob_pchazard)\n",
    "prob_coxcc = np.array(prob_coxcc)\n",
    "prob_dcsurvival = np.array(prob_dcsurvival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "gs = GridSpec(3, 2)\n",
    "colors = plt.cm.get_cmap(\"Dark2\")\n",
    "\n",
    "ax_calibration_curve = fig.add_subplot(gs[:1, :1])\n",
    "\n",
    "disp = CalibrationDisplay.from_predictions(y_l,prob_rsf, ax = ax_calibration_curve, name=\"RSF\", marker=\"o\")\n",
    "disp = CalibrationDisplay.from_predictions(y_l,prob_coxph, ax = ax_calibration_curve, name=\"CoxPH\", marker=\"s\")\n",
    "disp = CalibrationDisplay.from_predictions(y_l,prob_deepsurv, ax = ax_calibration_curve, name=\"DeepSurv\", marker=\"^\")\n",
    "disp = CalibrationDisplay.from_predictions(y_l,prob_deephit, ax = ax_calibration_curve, name=\"DeepHit\", marker=\"p\")\n",
    "disp = CalibrationDisplay.from_predictions(y_l,prob_pchazard, ax = ax_calibration_curve, name=\"PCHazard\", marker=\"*\")\n",
    "disp = CalibrationDisplay.from_predictions(y_l,prob_coxcc, ax = ax_calibration_curve, name=\"CoxCC\", marker=\"H\")\n",
    "disp = CalibrationDisplay.from_predictions(y_l,prob_dcsurvival, ax = ax_calibration_curve, name=\"DCSurvival\", marker=\"D\")\n",
    "\n",
    "ax_calibration_curve.set_xlabel(\"Mean Predicted Probability\", fontsize=14)\n",
    "ax_calibration_curve.set_ylabel(\"Fraction of Positives\", fontsize=14)\n",
    "ax_calibration_curve.legend(fontsize=10)\n",
    "\n",
    "# ax_calibration_curve.grid()\n",
    "#ax_calibration_curve.set_title(\"DD\")\n",
    "ax_calibration_curve.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
